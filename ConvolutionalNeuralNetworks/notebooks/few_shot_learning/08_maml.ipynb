{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-31T22:45:14.139972Z",
     "start_time": "2025-03-31T22:45:13.238324Z"
    }
   },
   "source": [
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from src.few_shot_learning import load_cinic10, calculate_accuracy, plot_confusion_matrix, set_seed\n",
    "set_seed(213)"
   ],
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "duplicate registrations for aten.linspace.Tensor_Tensor",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtimm\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mnn\u001B[39;00m\n",
      "File \u001B[0;32m/media/marta/Dane/Sem8/ConvolutionalNeuralNeutworks/.venv/lib/python3.10/site-packages/timm/__init__.py:2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mversion\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m __version__ \u001B[38;5;28;01mas\u001B[39;00m __version__\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlayers\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m      3\u001B[0m     is_scriptable \u001B[38;5;28;01mas\u001B[39;00m is_scriptable,\n\u001B[1;32m      4\u001B[0m     is_exportable \u001B[38;5;28;01mas\u001B[39;00m is_exportable,\n\u001B[1;32m      5\u001B[0m     set_scriptable \u001B[38;5;28;01mas\u001B[39;00m set_scriptable,\n\u001B[1;32m      6\u001B[0m     set_exportable \u001B[38;5;28;01mas\u001B[39;00m set_exportable,\n\u001B[1;32m      7\u001B[0m )\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m      9\u001B[0m     create_model \u001B[38;5;28;01mas\u001B[39;00m create_model,\n\u001B[1;32m     10\u001B[0m     list_models \u001B[38;5;28;01mas\u001B[39;00m list_models,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     17\u001B[0m     get_pretrained_cfg_value \u001B[38;5;28;01mas\u001B[39;00m get_pretrained_cfg_value,\n\u001B[1;32m     18\u001B[0m )\n",
      "File \u001B[0;32m/media/marta/Dane/Sem8/ConvolutionalNeuralNeutworks/.venv/lib/python3.10/site-packages/timm/layers/__init__.py:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mactivations\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01madaptive_avgmax_pool\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m \\\n\u001B[1;32m      3\u001B[0m     adaptive_avgmax_pool2d, select_adaptive_pool2d, AdaptiveAvgMaxPool2d, SelectAdaptivePool2d\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mattention2d\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m MultiQueryAttention2d, Attention2d, MultiQueryAttentionV2\n",
      "File \u001B[0;32m/media/marta/Dane/Sem8/ConvolutionalNeuralNeutworks/.venv/lib/python3.10/site-packages/timm/layers/activations.py:9\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;124;03m\"\"\" Activations\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \n\u001B[1;32m      3\u001B[0m \u001B[38;5;124;03mA collection of activations fn and modules with a common interface so that they can\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;124;03mHacked together by / Copyright 2020 Ross Wightman\u001B[39;00m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m----> 9\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m nn \u001B[38;5;28;01mas\u001B[39;00m nn\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m functional \u001B[38;5;28;01mas\u001B[39;00m F\n",
      "File \u001B[0;32m/media/marta/Dane/Sem8/ConvolutionalNeuralNeutworks/.venv/lib/python3.10/site-packages/torch/__init__.py:2604\u001B[0m\n\u001B[1;32m   2600\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunc\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m vmap \u001B[38;5;28;01mas\u001B[39;00m vmap\n\u001B[1;32m   2603\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m TYPE_CHECKING:\n\u001B[0;32m-> 2604\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m _meta_registrations\n\u001B[1;32m   2606\u001B[0m \u001B[38;5;66;03m# Enable CUDA Sanitizer\u001B[39;00m\n\u001B[1;32m   2607\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTORCH_CUDA_SANITIZER\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m os\u001B[38;5;241m.\u001B[39menviron:\n",
      "File \u001B[0;32m/media/marta/Dane/Sem8/ConvolutionalNeuralNeutworks/.venv/lib/python3.10/site-packages/torch/_meta_registrations.py:99\u001B[0m\n\u001B[1;32m     90\u001B[0m     broadcasted_shape \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m(_broadcast_shapes(self_shape, \u001B[38;5;241m*\u001B[39margs_shape))\n\u001B[1;32m     91\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_check(\n\u001B[1;32m     92\u001B[0m         broadcasted_shape \u001B[38;5;241m==\u001B[39m self_shape,\n\u001B[1;32m     93\u001B[0m         \u001B[38;5;28;01mlambda\u001B[39;00m: \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutput with shape \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mself_shape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m doesn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt match the broadcast shape \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbroadcasted_shape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     94\u001B[0m     )\n\u001B[1;32m     97\u001B[0m \u001B[38;5;129;43m@register_meta\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43maten\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinspace\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maten\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlogspace\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     98\u001B[0m \u001B[38;5;129;43m@out_wrapper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m---> 99\u001B[0m \u001B[38;5;28;43;01mdef\u001B[39;49;00m\u001B[38;5;250;43m \u001B[39;49m\u001B[38;5;21;43mmeta_linspace_logspace\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m    100\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstart\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    101\u001B[0m \u001B[43m    \u001B[49m\u001B[43mend\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    102\u001B[0m \u001B[43m    \u001B[49m\u001B[43msteps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    103\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbase\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    104\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    105\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    106\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlayout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstrided\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    107\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpin_memory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    108\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrequires_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    109\u001B[0m \u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m    110\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43misinstance\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mstart\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTensor\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m    111\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    112\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstart\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdim\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    113\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlinspace only supports 0-dimensional start and end tensors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    114\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/media/marta/Dane/Sem8/ConvolutionalNeuralNeutworks/.venv/lib/python3.10/site-packages/torch/_meta_registrations.py:54\u001B[0m, in \u001B[0;36mregister_meta.<locals>.wrapper\u001B[0;34m(fn)\u001B[0m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mregister\u001B[39m(op):\n\u001B[1;32m     52\u001B[0m     _add_op_to_registry(meta_table, op, fn)\n\u001B[0;32m---> 54\u001B[0m \u001B[43mpytree\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtree_map_\u001B[49m\u001B[43m(\u001B[49m\u001B[43mregister\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m fn\n",
      "File \u001B[0;32m/media/marta/Dane/Sem8/ConvolutionalNeuralNeutworks/.venv/lib/python3.10/site-packages/torch/utils/_pytree.py:1024\u001B[0m, in \u001B[0;36mtree_map_\u001B[0;34m(func, tree, is_leaf, *rests)\u001B[0m\n\u001B[1;32m   1022\u001B[0m leaves, treespec \u001B[38;5;241m=\u001B[39m tree_flatten(tree, is_leaf\u001B[38;5;241m=\u001B[39mis_leaf)\n\u001B[1;32m   1023\u001B[0m flat_args \u001B[38;5;241m=\u001B[39m [leaves] \u001B[38;5;241m+\u001B[39m [treespec\u001B[38;5;241m.\u001B[39mflatten_up_to(r) \u001B[38;5;28;01mfor\u001B[39;00m r \u001B[38;5;129;01min\u001B[39;00m rests]\n\u001B[0;32m-> 1024\u001B[0m \u001B[43mdeque\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mmap\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mflat_args\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmaxlen\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# consume and exhaust the iterable\u001B[39;00m\n\u001B[1;32m   1025\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m tree\n",
      "File \u001B[0;32m/media/marta/Dane/Sem8/ConvolutionalNeuralNeutworks/.venv/lib/python3.10/site-packages/torch/_meta_registrations.py:52\u001B[0m, in \u001B[0;36mregister_meta.<locals>.wrapper.<locals>.register\u001B[0;34m(op)\u001B[0m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mregister\u001B[39m(op):\n\u001B[0;32m---> 52\u001B[0m     \u001B[43m_add_op_to_registry\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmeta_table\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/media/marta/Dane/Sem8/ConvolutionalNeuralNeutworks/.venv/lib/python3.10/site-packages/torch/_decomp/__init__.py:95\u001B[0m, in \u001B[0;36m_add_op_to_registry\u001B[0;34m(registry, op, fn)\u001B[0m\n\u001B[1;32m     93\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m op_overload \u001B[38;5;129;01min\u001B[39;00m overloads:\n\u001B[1;32m     94\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m op_overload \u001B[38;5;129;01min\u001B[39;00m registry:\n\u001B[0;32m---> 95\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mduplicate registrations for \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mop_overload\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     96\u001B[0m     \u001B[38;5;66;03m# TorchScript dumps a bunch of extra nonsense overloads\u001B[39;00m\n\u001B[1;32m     97\u001B[0m     \u001B[38;5;66;03m# which don't have corresponding dispatcher entries, we need\u001B[39;00m\n\u001B[1;32m     98\u001B[0m     \u001B[38;5;66;03m# to filter those out, e.g aten.add.float_int\u001B[39;00m\n\u001B[1;32m     99\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39m_dispatch_has_kernel(op_overload\u001B[38;5;241m.\u001B[39mname()):\n",
      "\u001B[0;31mRuntimeError\u001B[0m: duplicate registrations for aten.linspace.Tensor_Tensor"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define a simple CNN model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ],
   "id": "e31444761d116940",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# MAML Algorithm\n",
    "class MAML(nn.Module):\n",
    "    def __init__(self, model, num_inner_steps=5, lr_inner=0.001, lr_outer=0.001, num_classes=10):\n",
    "        super(MAML, self).__init__()\n",
    "        self.model = model\n",
    "        self.num_inner_steps = num_inner_steps\n",
    "        self.lr_inner = lr_inner\n",
    "        self.lr_outer = lr_outer\n",
    "        self.num_classes = num_classes\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.outer_optimizer = optim.Adam(self.model.parameters(), lr=self.lr_outer)\n",
    "        # self.outer_optimizer = optim.Adam(self.model.parameters(), lr=self.lr_outer, weight_decay=1e-5)\n",
    "\n",
    "    def adapt(self, support_x, support_y):\n",
    "        # Instantiate a new ResNet18 model\n",
    "        model_copy = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "        model_copy.fc = nn.Linear(model_copy.fc.in_features, self.num_classes)  # Adjust the final layer for your dataset\n",
    "        \n",
    "        # Copy weights from the original model (ResNet18) to the new model\n",
    "        model_copy.load_state_dict(self.model.state_dict(), strict=False)\n",
    "\n",
    "        # Set the model to training mode\n",
    "        model_copy.train()\n",
    "\n",
    "        # Define optimizer for inner loop\n",
    "        # optimizer = optim.SGD(model_copy.parameters(), lr=self.lr_inner)\n",
    "        optimizer = optim.Adam(model_copy.parameters(), lr=self.lr_inner)\n",
    "\n",
    "        # Perform inner updates (adaptation)\n",
    "        for _ in range(self.num_inner_steps):\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model_copy(support_x)\n",
    "            loss = self.loss_fn(predictions, support_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        return model_copy\n",
    "\n",
    "    def meta_train(self, dataloader, epochs=10):\n",
    "        for epoch in range(epochs):\n",
    "            total_meta_loss = 0\n",
    "            total_correct = 0\n",
    "            total_samples = 0\n",
    "\n",
    "            for support_x, support_y in dataloader:\n",
    "                query_x, query_y = support_x.clone(), support_y.clone()\n",
    "                adapted_model = self.adapt(support_x, support_y)\n",
    "\n",
    "                # Perform the meta-update\n",
    "                self.outer_optimizer.zero_grad()\n",
    "                query_predictions = adapted_model(query_x)\n",
    "                meta_loss = self.loss_fn(query_predictions, query_y)\n",
    "                total_meta_loss += meta_loss.item()\n",
    "\n",
    "                # Calculate accuracy\n",
    "                _, predicted = torch.max(query_predictions, 1)\n",
    "                correct = (predicted == query_y).sum().item()\n",
    "                total_correct += correct\n",
    "                total_samples += query_y.size(0)\n",
    "\n",
    "                meta_loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=5.0)\n",
    "                self.outer_optimizer.step()\n",
    "\n",
    "            # Print loss and accuracy\n",
    "            accuracy = total_correct / total_samples * 100\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Meta-Loss: {total_meta_loss/len(dataloader):.4f}, Accuracy: {accuracy:.2f}%\")\n"
   ],
   "id": "40cd3aa81dcbd19f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = CNN(num_classes=10)\n",
    "maml = MAML(model)"
   ],
   "id": "8b36e9eb32bf0fba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_dir = \"../../data\"\n",
    "dataloader = load_cinic10(data_dir, few_shot_per_class=100, batch_size=128)"
   ],
   "id": "8ee93872f85627cf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "maml.meta_train(dataloader, epochs=30)",
   "id": "77abb509029f6a6f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train_accuracy = calculate_accuracy(model, data_dir, split='train')",
   "id": "b48831b75797ac95",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torchvision import models\n",
    "\n",
    "class ResNet18MAML(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ResNet18MAML, self).__init__()\n",
    "        self.resnet = models.resnet18(weights='IMAGENET1K_V1') # Use 'weights' instead of 'pretrained'\n",
    "        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, num_classes)  # Change output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)"
   ],
   "id": "265a543ba63f0138",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = ResNet18MAML(num_classes=10)\n",
    "maml = MAML(model)"
   ],
   "id": "24ba8d0d5054fab9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "maml.meta_train(dataloader, epochs=10)",
   "id": "abc9add7bc0eeae6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_accuracy = calculate_accuracy(model, data_dir, split='train')\n",
    "test_accuracy = calculate_accuracy(model, data_dir, split='test')"
   ],
   "id": "1cb6afd01b9f45c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "9d9d61601f0e4052",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
