{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-31T21:58:44.774454Z",
     "start_time": "2025-03-31T21:58:34.301713Z"
    }
   },
   "source": [
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from src.few_shot_learning import load_cinic10, calculate_accuracy, plot_confusion_matrix, set_seed\n",
    "set_seed(213)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T21:58:44.781636Z",
     "start_time": "2025-03-31T21:58:44.776126Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define a simple CNN model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ],
   "id": "e31444761d116940",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T22:28:03.817516Z",
     "start_time": "2025-03-31T22:28:03.810573Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# MAML Algorithm\n",
    "class MAML(nn.Module):\n",
    "    def __init__(self, model, num_inner_steps=5, lr_inner=0.001, lr_outer=0.0001, num_classes=10):\n",
    "        super(MAML, self).__init__()\n",
    "        self.model = model\n",
    "        self.num_inner_steps = num_inner_steps\n",
    "        self.lr_inner = lr_inner\n",
    "        self.lr_outer = lr_outer\n",
    "        self.num_classes = num_classes\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.outer_optimizer = optim.Adam(self.model.parameters(), lr=self.lr_outer)\n",
    "        # self.outer_optimizer = optim.Adam(self.model.parameters(), lr=self.lr_outer, weight_decay=1e-5)\n",
    "\n",
    "    def adapt(self, support_x, support_y):\n",
    "        # Instantiate a new ResNet18 model\n",
    "        model_copy = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "        model_copy.fc = nn.Linear(model_copy.fc.in_features, self.num_classes)  # Adjust the final layer for your dataset\n",
    "        \n",
    "        # Copy weights from the original model (ResNet18) to the new model\n",
    "        model_copy.load_state_dict(self.model.state_dict(), strict=False)\n",
    "\n",
    "        # Set the model to training mode\n",
    "        model_copy.train()\n",
    "\n",
    "        # Define optimizer for inner loop\n",
    "        # optimizer = optim.SGD(model_copy.parameters(), lr=self.lr_inner)\n",
    "        optimizer = optim.Adam(model_copy.parameters(), lr=self.lr_inner)\n",
    "\n",
    "        # Perform inner updates (adaptation)\n",
    "        for _ in range(self.num_inner_steps):\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model_copy(support_x)\n",
    "            loss = self.loss_fn(predictions, support_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        return model_copy\n",
    "\n",
    "    def meta_train(self, dataloader, epochs=10):\n",
    "        for epoch in range(epochs):\n",
    "            total_meta_loss = 0\n",
    "            total_correct = 0\n",
    "            total_samples = 0\n",
    "\n",
    "            for support_x, support_y in dataloader:\n",
    "                query_x, query_y = support_x.clone(), support_y.clone()\n",
    "                adapted_model = self.adapt(support_x, support_y)\n",
    "\n",
    "                # Perform the meta-update\n",
    "                self.outer_optimizer.zero_grad()\n",
    "                query_predictions = adapted_model(query_x)\n",
    "                meta_loss = self.loss_fn(query_predictions, query_y)\n",
    "                total_meta_loss += meta_loss.item()\n",
    "\n",
    "                # Calculate accuracy\n",
    "                _, predicted = torch.max(query_predictions, 1)\n",
    "                correct = (predicted == query_y).sum().item()\n",
    "                total_correct += correct\n",
    "                total_samples += query_y.size(0)\n",
    "\n",
    "                meta_loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=5.0)\n",
    "                self.outer_optimizer.step()\n",
    "\n",
    "            # Print loss and accuracy\n",
    "            accuracy = total_correct / total_samples * 100\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Meta-Loss: {total_meta_loss/len(dataloader):.4f}, Accuracy: {accuracy:.2f}%\")\n"
   ],
   "id": "40cd3aa81dcbd19f",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T21:58:44.801924Z",
     "start_time": "2025-03-31T21:58:44.793681Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = CNN(num_classes=10)\n",
    "maml = MAML(model)"
   ],
   "id": "8b36e9eb32bf0fba",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T21:58:45.022462Z",
     "start_time": "2025-03-31T21:58:44.803053Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_dir = \"../../data\"\n",
    "dataloader = load_cinic10(data_dir, few_shot_per_class=100, batch_size=128)"
   ],
   "id": "8ee93872f85627cf",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T21:58:47.157221Z",
     "start_time": "2025-03-31T21:58:45.023377Z"
    }
   },
   "cell_type": "code",
   "source": "maml.meta_train(dataloader, epochs=30)",
   "id": "77abb509029f6a6f",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for ResNet:\n\tsize mismatch for conv1.weight: copying a param with shape torch.Size([32, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 3, 7, 7]).",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mmaml\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmeta_train\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m30\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[3], line 47\u001B[0m, in \u001B[0;36mMAML.meta_train\u001B[0;34m(self, dataloader, epochs)\u001B[0m\n\u001B[1;32m     45\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m support_x, support_y \u001B[38;5;129;01min\u001B[39;00m dataloader:\n\u001B[1;32m     46\u001B[0m     query_x, query_y \u001B[38;5;241m=\u001B[39m support_x\u001B[38;5;241m.\u001B[39mclone(), support_y\u001B[38;5;241m.\u001B[39mclone()\n\u001B[0;32m---> 47\u001B[0m     adapted_model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madapt\u001B[49m\u001B[43m(\u001B[49m\u001B[43msupport_x\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msupport_y\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     49\u001B[0m     \u001B[38;5;66;03m# Perform the meta-update\u001B[39;00m\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mouter_optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n",
      "Cell \u001B[0;32mIn[3], line 20\u001B[0m, in \u001B[0;36mMAML.adapt\u001B[0;34m(self, support_x, support_y)\u001B[0m\n\u001B[1;32m     17\u001B[0m model_copy\u001B[38;5;241m.\u001B[39mfc \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mLinear(model_copy\u001B[38;5;241m.\u001B[39mfc\u001B[38;5;241m.\u001B[39min_features, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_classes)  \u001B[38;5;66;03m# Adjust the final layer for your dataset\u001B[39;00m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m# Copy weights from the original model (ResNet18) to the new model\u001B[39;00m\n\u001B[0;32m---> 20\u001B[0m \u001B[43mmodel_copy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_state_dict\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstate_dict\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstrict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;66;03m# Set the model to training mode\u001B[39;00m\n\u001B[1;32m     23\u001B[0m model_copy\u001B[38;5;241m.\u001B[39mtrain()\n",
      "File \u001B[0;32m/media/marta/Dane/Sem8/ConvolutionalNeuralNeutworks/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:2581\u001B[0m, in \u001B[0;36mModule.load_state_dict\u001B[0;34m(self, state_dict, strict, assign)\u001B[0m\n\u001B[1;32m   2573\u001B[0m         error_msgs\u001B[38;5;241m.\u001B[39minsert(\n\u001B[1;32m   2574\u001B[0m             \u001B[38;5;241m0\u001B[39m,\n\u001B[1;32m   2575\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMissing key(s) in state_dict: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m   2576\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mk\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m missing_keys)\n\u001B[1;32m   2577\u001B[0m             ),\n\u001B[1;32m   2578\u001B[0m         )\n\u001B[1;32m   2580\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(error_msgs) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m-> 2581\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m   2582\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mError(s) in loading state_dict for \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m   2583\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(error_msgs)\n\u001B[1;32m   2584\u001B[0m         )\n\u001B[1;32m   2585\u001B[0m     )\n\u001B[1;32m   2586\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Error(s) in loading state_dict for ResNet:\n\tsize mismatch for conv1.weight: copying a param with shape torch.Size([32, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 3, 7, 7])."
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train_accuracy = calculate_accuracy(model, data_dir, split='train')",
   "id": "b48831b75797ac95",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T21:59:20.189046Z",
     "start_time": "2025-03-31T21:59:20.185576Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchvision import models\n",
    "\n",
    "class ResNet18MAML(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ResNet18MAML, self).__init__()\n",
    "        self.resnet = models.resnet18(weights='IMAGENET1K_V1') # Use 'weights' instead of 'pretrained'\n",
    "        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, num_classes)  # Change output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)"
   ],
   "id": "265a543ba63f0138",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T22:28:07.747917Z",
     "start_time": "2025-03-31T22:28:07.602203Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = ResNet18MAML(num_classes=10)\n",
    "maml = MAML(model)"
   ],
   "id": "24ba8d0d5054fab9",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T22:33:09.041511Z",
     "start_time": "2025-03-31T22:28:09.291926Z"
    }
   },
   "cell_type": "code",
   "source": "maml.meta_train(dataloader, epochs=10)",
   "id": "abc9add7bc0eeae6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Meta-Loss: 0.0179, Accuracy: 100.00%\n",
      "Epoch 2/10, Meta-Loss: 0.0202, Accuracy: 100.00%\n",
      "Epoch 3/10, Meta-Loss: 0.0213, Accuracy: 100.00%\n",
      "Epoch 4/10, Meta-Loss: 0.0201, Accuracy: 100.00%\n",
      "Epoch 5/10, Meta-Loss: 0.0165, Accuracy: 100.00%\n",
      "Epoch 6/10, Meta-Loss: 0.0185, Accuracy: 100.00%\n",
      "Epoch 7/10, Meta-Loss: 0.0186, Accuracy: 100.00%\n",
      "Epoch 8/10, Meta-Loss: 0.0209, Accuracy: 100.00%\n",
      "Epoch 9/10, Meta-Loss: 0.0223, Accuracy: 100.00%\n",
      "Epoch 10/10, Meta-Loss: 0.0182, Accuracy: 100.00%\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T22:33:09.180410Z",
     "start_time": "2025-03-31T22:33:09.042604Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_accuracy = calculate_accuracy(model, data_dir, split='train', batch_size=8)\n",
    "test_accuracy = calculate_accuracy(model, data_dir, split='test', batch_size=8)"
   ],
   "id": "1cb6afd01b9f45c",
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.93 GiB of which 42.50 MiB is free. Process 16644 has 120.00 MiB memory in use. Process 20639 has 356.00 MiB memory in use. Process 24139 has 190.00 MiB memory in use. Process 31477 has 2.36 GiB memory in use. Process 34797 has 422.00 MiB memory in use. Including non-PyTorch memory, this process has 150.00 MiB memory in use. Of the allocated memory 77.00 MiB is allocated by PyTorch, and 11.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOutOfMemoryError\u001B[0m                          Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[25], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m train_accuracy \u001B[38;5;241m=\u001B[39m \u001B[43mcalculate_accuracy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msplit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtrain\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m8\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m test_accuracy \u001B[38;5;241m=\u001B[39m calculate_accuracy(model, data_dir, split\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtest\u001B[39m\u001B[38;5;124m'\u001B[39m, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m8\u001B[39m)\n",
      "File \u001B[0;32m/media/marta/Dane/Sem8/ConvolutionalNeuralNeutworks/src/few_shot_learning.py:49\u001B[0m, in \u001B[0;36mcalculate_accuracy\u001B[0;34m(model, data_root, split, batch_size)\u001B[0m\n\u001B[1;32m     44\u001B[0m     dataloader \u001B[38;5;241m=\u001B[39m DataLoader(few_shot_dataset, batch_size\u001B[38;5;241m=\u001B[39mbatch_size, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     46\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m dataloader\n\u001B[0;32m---> 49\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mcalculate_accuracy\u001B[39m(model, data_root, split\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtest\u001B[39m\u001B[38;5;124m'\u001B[39m, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m32\u001B[39m):\n\u001B[1;32m     50\u001B[0m     device \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     51\u001B[0m     model\u001B[38;5;241m.\u001B[39mto(device)\n",
      "File \u001B[0;32m/media/marta/Dane/Sem8/ConvolutionalNeuralNeutworks/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1343\u001B[0m, in \u001B[0;36mModule.to\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1340\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1341\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m\n\u001B[0;32m-> 1343\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/media/marta/Dane/Sem8/ConvolutionalNeuralNeutworks/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:903\u001B[0m, in \u001B[0;36mModule._apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    901\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[1;32m    902\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[0;32m--> 903\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    905\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[1;32m    906\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[1;32m    907\u001B[0m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[1;32m    908\u001B[0m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    913\u001B[0m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[1;32m    914\u001B[0m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[0;32m/media/marta/Dane/Sem8/ConvolutionalNeuralNeutworks/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:903\u001B[0m, in \u001B[0;36mModule._apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    901\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[1;32m    902\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[0;32m--> 903\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    905\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[1;32m    906\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[1;32m    907\u001B[0m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[1;32m    908\u001B[0m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    913\u001B[0m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[1;32m    914\u001B[0m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "    \u001B[0;31m[... skipping similar frames: Module._apply at line 903 (1 times)]\u001B[0m\n",
      "File \u001B[0;32m/media/marta/Dane/Sem8/ConvolutionalNeuralNeutworks/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:903\u001B[0m, in \u001B[0;36mModule._apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    901\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[1;32m    902\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[0;32m--> 903\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    905\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[1;32m    906\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[1;32m    907\u001B[0m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[1;32m    908\u001B[0m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    913\u001B[0m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[1;32m    914\u001B[0m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[0;32m/media/marta/Dane/Sem8/ConvolutionalNeuralNeutworks/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:930\u001B[0m, in \u001B[0;36mModule._apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    926\u001B[0m \u001B[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001B[39;00m\n\u001B[1;32m    927\u001B[0m \u001B[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001B[39;00m\n\u001B[1;32m    928\u001B[0m \u001B[38;5;66;03m# `with torch.no_grad():`\u001B[39;00m\n\u001B[1;32m    929\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m--> 930\u001B[0m     param_applied \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparam\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    931\u001B[0m p_should_use_set_data \u001B[38;5;241m=\u001B[39m compute_should_use_set_data(param, param_applied)\n\u001B[1;32m    933\u001B[0m \u001B[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001B[39;00m\n",
      "File \u001B[0;32m/media/marta/Dane/Sem8/ConvolutionalNeuralNeutworks/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1329\u001B[0m, in \u001B[0;36mModule.to.<locals>.convert\u001B[0;34m(t)\u001B[0m\n\u001B[1;32m   1322\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m convert_to_format \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m t\u001B[38;5;241m.\u001B[39mdim() \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;241m4\u001B[39m, \u001B[38;5;241m5\u001B[39m):\n\u001B[1;32m   1323\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(\n\u001B[1;32m   1324\u001B[0m             device,\n\u001B[1;32m   1325\u001B[0m             dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1326\u001B[0m             non_blocking,\n\u001B[1;32m   1327\u001B[0m             memory_format\u001B[38;5;241m=\u001B[39mconvert_to_format,\n\u001B[1;32m   1328\u001B[0m         )\n\u001B[0;32m-> 1329\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1330\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1331\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_floating_point\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_complex\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   1332\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnon_blocking\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1333\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1334\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m   1335\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(e) \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot copy out of meta tensor; no data!\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "\u001B[0;31mOutOfMemoryError\u001B[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.93 GiB of which 42.50 MiB is free. Process 16644 has 120.00 MiB memory in use. Process 20639 has 356.00 MiB memory in use. Process 24139 has 190.00 MiB memory in use. Process 31477 has 2.36 GiB memory in use. Process 34797 has 422.00 MiB memory in use. Including non-PyTorch memory, this process has 150.00 MiB memory in use. Of the allocated memory 77.00 MiB is allocated by PyTorch, and 11.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9d9d61601f0e4052"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
