{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal of this notebook is to improve previous attempts in a more structured way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aaa/Desktop/deep_learning/ConvolutionalNeuralNeutworks/venv_deep_learning/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "\n",
    "from helper_functions import train_step, test_step, accuracy_fn, print_train_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 213\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cinic_directory = '../data'\n",
    "cinic_train = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.ImageFolder(cinic_directory + '/train',\n",
    "    \ttransform=transforms.ToTensor()),\n",
    "    batch_size=64, shuffle=True)\n",
    "\n",
    "cinic_test = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.ImageFolder(cinic_directory + '/test',\n",
    "    \ttransform=transforms.ToTensor()),\n",
    "    batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedModel(nn.Module):\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Block 1: First set of convolutional layers\n",
    "        self.block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_shape, \n",
    "                      out_channels=hidden_units, \n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1), \n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(hidden_units),  # Add batch normalization\n",
    "            nn.Conv2d(in_channels=hidden_units, \n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(hidden_units),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)  # Reduce spatial dimensions\n",
    "        )\n",
    "        \n",
    "        # Block 2: Second set of convolutional layers\n",
    "        self.block_2 = nn.Sequential(\n",
    "            nn.Conv2d(hidden_units, hidden_units*2, 3, padding=1),  # Increase filter size\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(hidden_units*2),\n",
    "            nn.Conv2d(hidden_units*2, hidden_units*2, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(hidden_units*2),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        # Block 3: Third set of convolutional layers\n",
    "        self.block_3 = nn.Sequential(\n",
    "            nn.Conv2d(hidden_units*2, hidden_units*4, 3, padding=1),  # Increase filter size again\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(hidden_units*4),\n",
    "            nn.Conv2d(hidden_units*4, hidden_units*4, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(hidden_units*4),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        # Global Average Pooling to reduce the number of parameters\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        # Fully connected layer (classifier)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.5),  # Add dropout to prevent overfitting\n",
    "            nn.Linear(in_features=hidden_units*4, out_features=output_shape)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.block_1(x)\n",
    "        x = self.block_2(x)\n",
    "        x = self.block_3(x)\n",
    "        x = self.global_pool(x)  # Global average pooling\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EnhancedModel(input_shape=3, \n",
    "    hidden_units=10, \n",
    "    output_shape=10).to(device)\n",
    "\n",
    "\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "---------\n",
      "Train loss: 1.61706 | Train accuracy: 39.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:21<03:17, 21.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.51993 | Test accuracy: 44.36%\n",
      "\n",
      "Epoch: 1\n",
      "---------\n",
      "Train loss: 1.35976 | Train accuracy: 49.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:43<02:51, 21.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.33671 | Test accuracy: 50.42%\n",
      "\n",
      "Epoch: 2\n",
      "---------\n",
      "Train loss: 1.23492 | Train accuracy: 54.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [01:04<02:28, 21.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.22431 | Test accuracy: 55.28%\n",
      "\n",
      "Epoch: 3\n",
      "---------\n",
      "Train loss: 1.17339 | Train accuracy: 57.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [01:25<02:07, 21.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.17364 | Test accuracy: 57.79%\n",
      "\n",
      "Epoch: 4\n",
      "---------\n",
      "Train loss: 1.12367 | Train accuracy: 59.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [01:46<01:46, 21.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.14416 | Test accuracy: 59.01%\n",
      "\n",
      "Epoch: 5\n",
      "---------\n",
      "Train loss: 1.09122 | Train accuracy: 60.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [02:07<01:24, 21.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.18960 | Test accuracy: 57.20%\n",
      "\n",
      "Epoch: 6\n",
      "---------\n",
      "Train loss: 1.06329 | Train accuracy: 61.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [02:28<01:03, 21.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.15702 | Test accuracy: 58.61%\n",
      "\n",
      "Epoch: 7\n",
      "---------\n",
      "Train loss: 1.03701 | Train accuracy: 62.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [02:49<00:42, 21.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.13165 | Test accuracy: 59.59%\n",
      "\n",
      "Epoch: 8\n",
      "---------\n",
      "Train loss: 1.01783 | Train accuracy: 63.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [03:10<00:21, 21.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.14819 | Test accuracy: 58.69%\n",
      "\n",
      "Epoch: 9\n",
      "---------\n",
      "Train loss: 0.99918 | Train accuracy: 63.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [03:31<00:00, 21.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.13444 | Test accuracy: 59.67%\n",
      "\n",
      "\n",
      "Train time on cuda: 211.969 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "train_time_start_model_2 = timer()\n",
    "\n",
    "# Train and test model \n",
    "epochs = 10\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch}\\n---------\")\n",
    "    train_step(data_loader=cinic_train, \n",
    "        model=model, \n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device=device\n",
    "    )\n",
    "    test_step(data_loader=cinic_test,\n",
    "        model=model,\n",
    "        loss_fn=loss_fn,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "train_time_end_model_2 = timer()\n",
    "total_train_time_model_2 = print_train_time(start=train_time_start_model_2,\n",
    "                                           end=train_time_end_model_2,\n",
    "                                           device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
