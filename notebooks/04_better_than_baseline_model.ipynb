{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal of this notebook is to improve previous attempts in a more structured way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class EnhancedModel(nn.Module):\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Block 1: First set of convolutional layers\n",
    "        self.block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_shape, \n",
    "                      out_channels=hidden_units, \n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1), \n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(hidden_units),  # Add batch normalization\n",
    "            nn.Conv2d(in_channels=hidden_units, \n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(hidden_units),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)  # Reduce spatial dimensions\n",
    "        )\n",
    "        \n",
    "        # Block 2: Second set of convolutional layers\n",
    "        self.block_2 = nn.Sequential(\n",
    "            nn.Conv2d(hidden_units, hidden_units*2, 3, padding=1),  # Increase filter size\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(hidden_units*2),\n",
    "            nn.Conv2d(hidden_units*2, hidden_units*2, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(hidden_units*2),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        # Block 3: Third set of convolutional layers\n",
    "        self.block_3 = nn.Sequential(\n",
    "            nn.Conv2d(hidden_units*2, hidden_units*4, 3, padding=1),  # Increase filter size again\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(hidden_units*4),\n",
    "            nn.Conv2d(hidden_units*4, hidden_units*4, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(hidden_units*4),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        # Global Average Pooling to reduce the number of parameters\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        # Fully connected layer (classifier)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.5),  # Add dropout to prevent overfitting\n",
    "            nn.Linear(in_features=hidden_units*4, out_features=output_shape)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.block_1(x)\n",
    "        x = self.block_2(x)\n",
    "        x = self.block_3(x)\n",
    "        x = self.global_pool(x)  # Global average pooling\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
