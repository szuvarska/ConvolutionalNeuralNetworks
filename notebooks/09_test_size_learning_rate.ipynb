{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "from baseline_model import BaselineModel\n",
    "from enhanced_model import EnhancedModel\n",
    "from helper_functions import run_model\n",
    "from plots_functions import (\n",
    "    multiple_runs_with_uncertainty_band,\n",
    "    multiple_runs_with_every_run,\n",
    ")\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "data_loader_args = {\n",
    "    \"batch_size\": 64,\n",
    "    \"shuffle\": True,\n",
    "    \"num_workers\": 6,\n",
    "    \"pin_memory\": True,\n",
    "    \"persistent_workers\": True,\n",
    "}\n",
    "\n",
    "\n",
    "seed = 213\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial setup\n",
    "metadata = \"\"\"all runs have 30 epochs, learning rate 0.01, each combination was run 5 times, \n",
    "4 dropout rates were tested [0, 0.25, 0.5, 0.75], and 5 L2 regularization parameters [0, 0.0001, 0.001, 0.01, 0.05], \n",
    "sgd optimizer with momentum 0.9 and Baseline model with 15 hidden units\"\"\"\n",
    "epochs = 30\n",
    "lr = 0.01\n",
    "num_of_repeats = 5\n",
    "dropouts = [0, 0.25, 0.5, 0.75]\n",
    "regularizations = [0, 0.0001, 0.001, 0.01, 0.05]\n",
    "experiment_dict = {\n",
    "    \"experiment name\": \"regularization\",\n",
    "    \"experiments metadata\": metadata,\n",
    "}\n",
    "if \"regularization.pkl\" not in os.listdir(\"../results\"):\n",
    "    pickle.dump(experiment_dict, open(\"../results/regularization.pkl\", \"wb\"))\n",
    "else:\n",
    "    raise FileExistsError(\"File already exists, this notebook does not i\")\n",
    "\n",
    "# time and progress\n",
    "start_time = time.time()\n",
    "total_number_of_runs = num_of_repeats * len(regularizations) * len(dropouts)\n",
    "number_of_completed_runs = 0\n",
    "\n",
    "cinic_directory = \"../data\"\n",
    "cinic_train = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.ImageFolder(\n",
    "        cinic_directory + \"/train\", transform=transforms.ToTensor()\n",
    "    ),\n",
    "    **data_loader_args,\n",
    ")\n",
    "\n",
    "cinic_test = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.ImageFolder(\n",
    "        cinic_directory + \"/test\", transform=transforms.ToTensor()\n",
    "    ),\n",
    "    **data_loader_args,\n",
    ")\n",
    "\n",
    "for dropout in dropouts:\n",
    "    for regularization in regularizations:\n",
    "        experiment_dict = pickle.load(open(\"../results/regularization.pkl\", \"rb\"))\n",
    "        metrics_list = []\n",
    "        total_time_list = []\n",
    "        for i in range(num_of_repeats):\n",
    "            model = BaselineModel(\n",
    "                input_shape=3, hidden_units=15, output_shape=10, dropout_p=dropout\n",
    "            ).to(device)\n",
    "\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            optimizer = torch.optim.SGD(\n",
    "                params=model.parameters(),\n",
    "                lr=lr,\n",
    "                momentum=0.9,\n",
    "                weight_decay=regularization,\n",
    "            )\n",
    "\n",
    "            metrics, total_time = run_model(\n",
    "                cinic_train,\n",
    "                cinic_test,\n",
    "                model,\n",
    "                loss_fn,\n",
    "                optimizer,\n",
    "                device=device,\n",
    "                epochs=epochs,\n",
    "            )\n",
    "\n",
    "            metrics_list.append(metrics)\n",
    "            total_time_list.append(total_time)\n",
    "\n",
    "        experiment_dict[(dropout, regularization)] = metrics_list\n",
    "        pickle.dump(experiment_dict, open(\"../results/regularization.pkl\", \"wb\"))\n",
    "        number_of_completed_runs += 1\n",
    "        seconds = time.time() - start_time\n",
    "        hours = int(seconds // 3600)\n",
    "        minutes = int((seconds % 3600) // 60)\n",
    "        print(\n",
    "            f\"{number_of_completed_runs}/{total_number_of_runs} ({round(100* number_of_completed_runs/total_number_of_runs)}%) done, runs {hours}h:{minutes}min\"\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
