{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-17T15:12:23.100700Z",
     "start_time": "2025-03-17T15:12:23.097789Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import os\n",
    "import random\n",
    "from src.helper_functions import train_step, test_step, accuracy_fn"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T15:07:51.712400Z",
     "start_time": "2025-03-17T15:07:51.708034Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the CNN backbone\n",
    "class CNNFewShot(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CNNFewShot, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 256)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = self.pool(self.relu(self.conv3(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ],
   "id": "ed99634b6ed285d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T15:11:22.647605Z",
     "start_time": "2025-03-17T15:11:22.643279Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load CINIC-10 dataset\n",
    "def load_cinic10(data_root, split='train', few_shot_per_class=10, batch_size=16):\n",
    "    data_dir = os.path.join(data_root, \"cinic-10\", split)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((32, 32)),  # Ensure images are 32x32\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "    \n",
    "    dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "    \n",
    "    # Few-shot sampling\n",
    "    class_indices = {label: [] for label in range(10)}\n",
    "    for idx, (_, label) in enumerate(dataset.samples):\n",
    "        class_indices[label].append(idx)\n",
    "\n",
    "    few_shot_indices = []\n",
    "    for indices in class_indices.values():\n",
    "        few_shot_indices.extend(random.sample(indices, min(len(indices), few_shot_per_class)))  # Handle cases where a class has fewer than few_shot_per_class images\n",
    "\n",
    "    few_shot_dataset = Subset(dataset, few_shot_indices)\n",
    "    dataloader = DataLoader(few_shot_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return dataloader"
   ],
   "id": "786ef165d977099b",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T15:07:51.723408Z",
     "start_time": "2025-03-17T15:07:51.719084Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train the CNN on few-shot data\n",
    "def train_few_shot(model, dataloader, epochs=10, lr=0.001):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss:.4f}\")"
   ],
   "id": "bd53b0380def2545",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T15:12:29.848075Z",
     "start_time": "2025-03-17T15:12:28.605111Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_dir = \"../data\"\n",
    "dataloader = load_cinic10(data_dir, few_shot_per_class=10)\n",
    "model = CNNFewShot(num_classes=10)\n",
    "train_few_shot(model, dataloader)"
   ],
   "id": "a248242ebf22f4f4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 16.2679\n",
      "Epoch 2/10, Loss: 16.0916\n",
      "Epoch 3/10, Loss: 16.0031\n",
      "Epoch 4/10, Loss: 15.6597\n",
      "Epoch 5/10, Loss: 15.1344\n",
      "Epoch 6/10, Loss: 14.4928\n",
      "Epoch 7/10, Loss: 14.3576\n",
      "Epoch 8/10, Loss: 14.4622\n",
      "Epoch 9/10, Loss: 13.9526\n",
      "Epoch 10/10, Loss: 12.3100\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "70596cfd8b8edca9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
